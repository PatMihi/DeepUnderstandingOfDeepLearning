{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhWV8oes-wKR"
   },
   "source": [
    "# COURSE: A deep understanding of deep learning\n",
    "## SECTION: Overfitting, cross-validation, regularization\n",
    "### LECTURE: Cross-validation -- manual separation\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com\n",
    "##### COURSE URL: udemy.com/course/deeplearning_x/?couponCode=202401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "YeuAheYyhdZw"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "MU7rvmWuhjud"
   },
   "outputs": [],
   "source": [
    "# import dataset\n",
    "import pandas as pd\n",
    "iris = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')\n",
    "\n",
    "\n",
    "# convert from pandas dataframe to tensor\n",
    "data = torch.tensor( iris[iris.columns[0:4]].values ).float()\n",
    "\n",
    "# transform species to number\n",
    "labels = torch.zeros(len(data), dtype=torch.long)\n",
    "# labels[iris.species=='setosa'] = 0 # don't need!\n",
    "labels[iris.species=='versicolor'] = 1\n",
    "labels[iris.species=='virginica'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "nLabels = len(np.unique(labels.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JiAFAHB20DQc"
   },
   "source": [
    "# Separate data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "mwhgV43SXbCN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  (no devset here)\n",
    "\n",
    "# how many training examples\n",
    "propTraining = .8 # in proportion, not percent\n",
    "nTraining = int(len(labels)*propTraining)\n",
    "\n",
    "# initialize a boolean vector to select data and labels\n",
    "traintestBool = np.zeros(len(labels),dtype=bool)\n",
    "\n",
    "# is this the correct way to select samples?\n",
    "#traintestBool[range(nTraining)] = True\n",
    "\n",
    "# this is better, but why?\n",
    "#items2use4train = np.random.choice(range(len(labels)),nTraining,replace=False)\n",
    "#traintestBool[items2use4train] = True\n",
    "\n",
    "traintestBool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.int64(4), np.int64(1), np.int64(15), np.int64(20), np.int64(45), np.int64(31), np.int64(49), np.int64(36), np.int64(32), np.int64(3), np.int64(29), np.int64(21), np.int64(0), np.int64(30), np.int64(34), np.int64(22), np.int64(39), np.int64(12), np.int64(46), np.int64(48), np.int64(35), np.int64(47), np.int64(26), np.int64(7), np.int64(19), np.int64(11), np.int64(18), np.int64(43), np.int64(40), np.int64(33), np.int64(37), np.int64(17), np.int64(28), np.int64(44), np.int64(25), np.int64(27), np.int64(2), np.int64(10), np.int64(8), np.int64(5), np.int64(54), np.int64(51), np.int64(65), np.int64(70), np.int64(95), np.int64(81), np.int64(99), np.int64(86), np.int64(82), np.int64(53), np.int64(79), np.int64(71), np.int64(50), np.int64(80), np.int64(84), np.int64(72), np.int64(89), np.int64(62), np.int64(96), np.int64(98), np.int64(85), np.int64(97), np.int64(76), np.int64(57), np.int64(69), np.int64(61), np.int64(68), np.int64(93), np.int64(90), np.int64(83), np.int64(87), np.int64(67), np.int64(78), np.int64(94), np.int64(75), np.int64(77), np.int64(52), np.int64(60), np.int64(58), np.int64(55), np.int64(104), np.int64(101), np.int64(115), np.int64(120), np.int64(145), np.int64(131), np.int64(149), np.int64(136), np.int64(132), np.int64(103), np.int64(129), np.int64(121), np.int64(100), np.int64(130), np.int64(134), np.int64(122), np.int64(139), np.int64(112), np.int64(146), np.int64(148), np.int64(135), np.int64(147), np.int64(126), np.int64(107), np.int64(119), np.int64(111), np.int64(118), np.int64(143), np.int64(140), np.int64(133), np.int64(137), np.int64(117), np.int64(128), np.int64(144), np.int64(125), np.int64(127), np.int64(102), np.int64(110), np.int64(108), np.int64(105)]\n"
     ]
    }
   ],
   "source": [
    "full_train = []\n",
    "\n",
    "for i in range(nLabels):\n",
    "    train_group = train_numbers -1 + 50 * i\n",
    "    full_train.extend(train_group)  # Use extend to add elements to the list\n",
    "\n",
    "print(full_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintestBool2 = np.zeros(len(labels), dtype=bool)\n",
    "traintestBool2[full_train] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of full data:\n",
      "tensor(1.)\n",
      " \n",
      "Average of training data:\n",
      "tensor(1.)\n",
      " \n",
      "Average of test data:\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# test whether it's balanced\n",
    "print('Average of full data:')\n",
    "print( torch.mean(labels.float()) ) # =1 by definition\n",
    "print(' ')\n",
    "\n",
    "print('Average of training data:')\n",
    "print( torch.mean(labels[traintestBool2].float()) ) # should be 1...\n",
    "print(' ')\n",
    "\n",
    "print('Average of test data:')\n",
    "print( torch.mean(labels[~traintestBool2].float()) ) # should also be 1..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "LPcj_f92bYs0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of full data:\n",
      "tensor(1.)\n",
      " \n",
      "Average of training data:\n",
      "tensor(1.)\n",
      " \n",
      "Average of test data:\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# test whether it's balanced\n",
    "print('Average of full data:')\n",
    "print( torch.mean(labels.float()) ) # =1 by definition\n",
    "print(' ')\n",
    "\n",
    "print('Average of training data:')\n",
    "print( torch.mean(labels[traintestBool].float()) ) # should be 1...\n",
    "print(' ')\n",
    "\n",
    "print('Average of test data:')\n",
    "print( torch.mean(labels[~traintestBool].float()) ) # should also be 1..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "v0JMIGb1iV_9"
   },
   "outputs": [],
   "source": [
    "# create the ANN model\n",
    "\n",
    "# model architecture\n",
    "ANNiris = nn.Sequential(\n",
    "    nn.Linear(4,64),   # input layer\n",
    "    nn.ReLU(),         # activation unit\n",
    "    nn.Linear(64,64),  # hidden layer\n",
    "    nn.ReLU(),         # activation unit\n",
    "    nn.Linear(64,3),   # output units\n",
    "      )\n",
    "\n",
    "# loss function\n",
    "lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(ANNiris.parameters(),lr=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4, out_features=64, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=64, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANNiris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "iyxr6_P9b-x5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150, 4])\n",
      "torch.Size([120, 4])\n",
      "torch.Size([30, 4])\n"
     ]
    }
   ],
   "source": [
    "# entire dataset\n",
    "print( data.shape )\n",
    "\n",
    "# training set\n",
    "print( data[traintestBool,:].shape )\n",
    "\n",
    "# test set\n",
    "print( data[~traintestBool,:].shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbx3Zkc_0UT8"
   },
   "source": [
    "# Train and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "cVD1nFTli7TO"
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "\n",
    "numepochs = 1000\n",
    "\n",
    "# initialize losses\n",
    "losses = torch.zeros(numepochs)\n",
    "ongoingAcc = []\n",
    "\n",
    "# loop over epochs\n",
    "for epochi in range(numepochs):\n",
    "\n",
    "  # forward pass\n",
    "  yHat = ANNiris(data[traintestBool,:])\n",
    "\n",
    "  # compute accuracy (note: denser than previous code!)\n",
    "  ongoingAcc.append( 100*torch.mean(\n",
    "              (torch.argmax(yHat,axis=1) == labels[traintestBool]).float()) )\n",
    "\n",
    "  # compute loss\n",
    "  loss = lossfun(yHat,labels[traintestBool])\n",
    "  losses[epochi] = loss\n",
    "\n",
    "  # backprop\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "vXku7xIdcu7Y"
   },
   "outputs": [],
   "source": [
    "# compute train and test accuracies\n",
    "\n",
    "# final forward pass USING TRAINING DATA\n",
    "predictions = ANNiris(data[traintestBool,:])\n",
    "trainacc = 100*torch.mean((torch.argmax(predictions,axis=1) == labels[traintestBool]).float())\n",
    "\n",
    "\n",
    "# final forward pass USING TEST DATA!\n",
    "predictions = ANNiris(data[~traintestBool,:])\n",
    "testacc = 100*torch.mean((torch.argmax(predictions,axis=1) == labels[~traintestBool]).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "JYouZAY4i3jM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final TRAIN accuracy: 98.3333%\n",
      "Final TEST accuracy:  73.3333%\n"
     ]
    }
   ],
   "source": [
    "# report accuracies\n",
    "\n",
    "print('Final TRAIN accuracy: %g%%' %trainacc)\n",
    "print('Final TEST accuracy:  %g%%' %testacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "kcbD9nZmd9nu"
   },
   "outputs": [],
   "source": [
    "# normally also inspect losses and accuracy by epoch, etc etc etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[~traintestBool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 1, 2, 1, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(predictions,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "MAzQqbq8fqSt"
   },
   "outputs": [],
   "source": [
    "# final forward pass USING TEST DATA!\n",
    "predictions_full = ANNiris(data)\n",
    "testacc = 100*torch.mean((torch.argmax(predictions_full,axis=1) == labels).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(93.3333)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label  Prediction\n",
       "0        0           0\n",
       "1        0           0\n",
       "2        0           0\n",
       "3        0           0\n",
       "4        0           0\n",
       "..     ...         ...\n",
       "145      2           2\n",
       "146      2           2\n",
       "147      2           2\n",
       "148      2           2\n",
       "149      2           2\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert labels and predictions_full to numpy arrays\n",
    "labels_np = labels.numpy()\n",
    "predictions_full_np = torch.argmax(predictions_full, axis=1).numpy()\n",
    "\n",
    "# Create a dataframe\n",
    "df_results = pd.DataFrame({\n",
    "    'Label': labels_np,\n",
    "    'Prediction': predictions_full_np\n",
    "})\n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[\"Correct\"] = (df_results[\"Label\"] == df_results[\"Prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[\"Correct\"] = df_results[\"Correct\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Correct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.02</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.82</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Prediction  Correct\n",
       "Label                     \n",
       "0            0.00     1.00\n",
       "1            1.02     0.98\n",
       "2            1.82     0.82"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.groupby(\"Label\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwTbABK7fqzZ"
   },
   "source": [
    "# Additional explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_train_test_split(data, labels, propTraining):\n",
    "    unique_labels = torch.unique(labels)\n",
    "    train_indices = []\n",
    "    test_indices = []\n",
    "\n",
    "    for label in unique_labels:\n",
    "        label_indices = torch.where(labels == label)[0]\n",
    "        n_train = int(len(label_indices) * propTraining)\n",
    "        train_indices.extend(np.random.choice(label_indices, n_train, replace=False))\n",
    "        test_indices.extend(list(set(label_indices.numpy()) - set(train_indices)))\n",
    "\n",
    "    return train_indices, test_indices\n",
    "\n",
    "train_indices, test_indices = balanced_train_test_split(data, labels, propTraining)\n",
    "\n",
    "# Create boolean mask for train/test split\n",
    "traintestBool = np.zeros(len(labels), dtype=bool)\n",
    "traintestBool[train_indices] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.int64(40),\n",
       " np.int64(16),\n",
       " np.int64(7),\n",
       " np.int64(41),\n",
       " np.int64(25),\n",
       " np.int64(44),\n",
       " np.int64(46),\n",
       " np.int64(1),\n",
       " np.int64(28),\n",
       " np.int64(20),\n",
       " np.int64(13),\n",
       " np.int64(14),\n",
       " np.int64(21),\n",
       " np.int64(26),\n",
       " np.int64(35),\n",
       " np.int64(11),\n",
       " np.int64(10),\n",
       " np.int64(34),\n",
       " np.int64(17),\n",
       " np.int64(27),\n",
       " np.int64(47),\n",
       " np.int64(18),\n",
       " np.int64(23),\n",
       " np.int64(38),\n",
       " np.int64(37),\n",
       " np.int64(5),\n",
       " np.int64(31),\n",
       " np.int64(32),\n",
       " np.int64(42),\n",
       " np.int64(33),\n",
       " np.int64(6),\n",
       " np.int64(12),\n",
       " np.int64(48),\n",
       " np.int64(19),\n",
       " np.int64(36),\n",
       " np.int64(49),\n",
       " np.int64(8),\n",
       " np.int64(30),\n",
       " np.int64(4),\n",
       " np.int64(2),\n",
       " np.int64(50),\n",
       " np.int64(81),\n",
       " np.int64(82),\n",
       " np.int64(80),\n",
       " np.int64(61),\n",
       " np.int64(77),\n",
       " np.int64(93),\n",
       " np.int64(70),\n",
       " np.int64(83),\n",
       " np.int64(59),\n",
       " np.int64(60),\n",
       " np.int64(88),\n",
       " np.int64(91),\n",
       " np.int64(84),\n",
       " np.int64(58),\n",
       " np.int64(96),\n",
       " np.int64(62),\n",
       " np.int64(95),\n",
       " np.int64(90),\n",
       " np.int64(99),\n",
       " np.int64(51),\n",
       " np.int64(78),\n",
       " np.int64(66),\n",
       " np.int64(67),\n",
       " np.int64(75),\n",
       " np.int64(55),\n",
       " np.int64(87),\n",
       " np.int64(73),\n",
       " np.int64(89),\n",
       " np.int64(56),\n",
       " np.int64(52),\n",
       " np.int64(63),\n",
       " np.int64(69),\n",
       " np.int64(64),\n",
       " np.int64(68),\n",
       " np.int64(53),\n",
       " np.int64(71),\n",
       " np.int64(86),\n",
       " np.int64(76),\n",
       " np.int64(54),\n",
       " np.int64(107),\n",
       " np.int64(125),\n",
       " np.int64(106),\n",
       " np.int64(149),\n",
       " np.int64(102),\n",
       " np.int64(117),\n",
       " np.int64(144),\n",
       " np.int64(112),\n",
       " np.int64(122),\n",
       " np.int64(116),\n",
       " np.int64(129),\n",
       " np.int64(127),\n",
       " np.int64(128),\n",
       " np.int64(132),\n",
       " np.int64(140),\n",
       " np.int64(148),\n",
       " np.int64(103),\n",
       " np.int64(119),\n",
       " np.int64(145),\n",
       " np.int64(115),\n",
       " np.int64(105),\n",
       " np.int64(120),\n",
       " np.int64(146),\n",
       " np.int64(147),\n",
       " np.int64(139),\n",
       " np.int64(111),\n",
       " np.int64(100),\n",
       " np.int64(135),\n",
       " np.int64(138),\n",
       " np.int64(104),\n",
       " np.int64(137),\n",
       " np.int64(123),\n",
       " np.int64(113),\n",
       " np.int64(133),\n",
       " np.int64(131),\n",
       " np.int64(134),\n",
       " np.int64(143),\n",
       " np.int64(141),\n",
       " np.int64(124),\n",
       " np.int64(121)]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(labels == 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]),)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(labels == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])\n",
      "40\n",
      "[np.int64(40), np.int64(16), np.int64(7), np.int64(41), np.int64(25), np.int64(44), np.int64(46), np.int64(1), np.int64(28), np.int64(20), np.int64(13), np.int64(14), np.int64(21), np.int64(26), np.int64(35), np.int64(11), np.int64(10), np.int64(34), np.int64(17), np.int64(27), np.int64(47), np.int64(18), np.int64(23), np.int64(38), np.int64(37), np.int64(5), np.int64(31), np.int64(32), np.int64(42), np.int64(33), np.int64(6), np.int64(12), np.int64(48), np.int64(19), np.int64(36), np.int64(49), np.int64(8), np.int64(30), np.int64(4), np.int64(2)]\n",
      "[np.int64(0), np.int64(3), np.int64(39), np.int64(9), np.int64(43), np.int64(45), np.int64(15), np.int64(22), np.int64(24), np.int64(29)]\n",
      "tensor(1)\n",
      "tensor([50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
      "        68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
      "        86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n",
      "40\n",
      "[np.int64(40), np.int64(16), np.int64(7), np.int64(41), np.int64(25), np.int64(44), np.int64(46), np.int64(1), np.int64(28), np.int64(20), np.int64(13), np.int64(14), np.int64(21), np.int64(26), np.int64(35), np.int64(11), np.int64(10), np.int64(34), np.int64(17), np.int64(27), np.int64(47), np.int64(18), np.int64(23), np.int64(38), np.int64(37), np.int64(5), np.int64(31), np.int64(32), np.int64(42), np.int64(33), np.int64(6), np.int64(12), np.int64(48), np.int64(19), np.int64(36), np.int64(49), np.int64(8), np.int64(30), np.int64(4), np.int64(2), np.int64(50), np.int64(81), np.int64(82), np.int64(80), np.int64(61), np.int64(77), np.int64(93), np.int64(70), np.int64(83), np.int64(59), np.int64(60), np.int64(88), np.int64(91), np.int64(84), np.int64(58), np.int64(96), np.int64(62), np.int64(95), np.int64(90), np.int64(99), np.int64(51), np.int64(78), np.int64(66), np.int64(67), np.int64(75), np.int64(55), np.int64(87), np.int64(73), np.int64(89), np.int64(56), np.int64(52), np.int64(63), np.int64(69), np.int64(64), np.int64(68), np.int64(53), np.int64(71), np.int64(86), np.int64(76), np.int64(54)]\n",
      "[np.int64(0), np.int64(3), np.int64(39), np.int64(9), np.int64(43), np.int64(45), np.int64(15), np.int64(22), np.int64(24), np.int64(29), np.int64(65), np.int64(97), np.int64(98), np.int64(72), np.int64(74), np.int64(79), np.int64(85), np.int64(57), np.int64(92), np.int64(94)]\n",
      "tensor(2)\n",
      "tensor([100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
      "        114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
      "        128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149])\n",
      "40\n",
      "[np.int64(40), np.int64(16), np.int64(7), np.int64(41), np.int64(25), np.int64(44), np.int64(46), np.int64(1), np.int64(28), np.int64(20), np.int64(13), np.int64(14), np.int64(21), np.int64(26), np.int64(35), np.int64(11), np.int64(10), np.int64(34), np.int64(17), np.int64(27), np.int64(47), np.int64(18), np.int64(23), np.int64(38), np.int64(37), np.int64(5), np.int64(31), np.int64(32), np.int64(42), np.int64(33), np.int64(6), np.int64(12), np.int64(48), np.int64(19), np.int64(36), np.int64(49), np.int64(8), np.int64(30), np.int64(4), np.int64(2), np.int64(50), np.int64(81), np.int64(82), np.int64(80), np.int64(61), np.int64(77), np.int64(93), np.int64(70), np.int64(83), np.int64(59), np.int64(60), np.int64(88), np.int64(91), np.int64(84), np.int64(58), np.int64(96), np.int64(62), np.int64(95), np.int64(90), np.int64(99), np.int64(51), np.int64(78), np.int64(66), np.int64(67), np.int64(75), np.int64(55), np.int64(87), np.int64(73), np.int64(89), np.int64(56), np.int64(52), np.int64(63), np.int64(69), np.int64(64), np.int64(68), np.int64(53), np.int64(71), np.int64(86), np.int64(76), np.int64(54), np.int64(107), np.int64(125), np.int64(106), np.int64(149), np.int64(102), np.int64(117), np.int64(144), np.int64(112), np.int64(122), np.int64(116), np.int64(129), np.int64(127), np.int64(128), np.int64(132), np.int64(140), np.int64(148), np.int64(103), np.int64(119), np.int64(145), np.int64(115), np.int64(105), np.int64(120), np.int64(146), np.int64(147), np.int64(139), np.int64(111), np.int64(100), np.int64(135), np.int64(138), np.int64(104), np.int64(137), np.int64(123), np.int64(113), np.int64(133), np.int64(131), np.int64(134), np.int64(143), np.int64(141), np.int64(124), np.int64(121)]\n",
      "[np.int64(0), np.int64(3), np.int64(39), np.int64(9), np.int64(43), np.int64(45), np.int64(15), np.int64(22), np.int64(24), np.int64(29), np.int64(65), np.int64(97), np.int64(98), np.int64(72), np.int64(74), np.int64(79), np.int64(85), np.int64(57), np.int64(92), np.int64(94), np.int64(130), np.int64(101), np.int64(136), np.int64(108), np.int64(109), np.int64(142), np.int64(110), np.int64(114), np.int64(118), np.int64(126)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "unique_labels = torch.unique(labels)\n",
    "train_indices = []\n",
    "test_indices = []\n",
    "\n",
    "for label in unique_labels:\n",
    "    print(label)\n",
    "    label_indices = torch.where(labels == label)[0]\n",
    "    print(label_indices)\n",
    "    n_train = int(len(label_indices) * propTraining)\n",
    "    print(n_train)\n",
    "    train_indices.extend(np.random.choice(label_indices, n_train, replace=False))\n",
    "    print(train_indices)\n",
    "    test_indices.extend(list(set(label_indices.numpy()) - set(train_indices)))\n",
    "    print(test_indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "jWC_SDDCfrAo"
   },
   "outputs": [],
   "source": [
    "# 1) Randomly assigning data samples to be in the train vs test phase produced a statistical balance, but it was\n",
    "#    not perfect. Write an algorithm that will guarantee a balance of flower types while also randomly assigning\n",
    "#    samples to be in train vs. test.\n",
    "#\n",
    "# 2) Revert the code to its original form -- with the strong imbalance in flower types. Then train the model. What are\n",
    "#    the train and test accuracies? Compute the accuracy separately for each type of flower to see whether the model\n",
    "#    learned some categories, or whether it performed equally on all three categories. Are you surprised at the results?\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1YpHocGI4rApOxIBb1ZghCU5L-hFnv4CK",
     "timestamp": 1616608248670
    }
   ]
  },
  "kernelspec": {
   "display_name": "MLFlow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
